---
title: "viz.qmd"
format: html
editor: source
---

# Synopsis
This file tracks the works related to the visualizations for the golem app. Renv 
is not working well with r2u for binary on Ubuntu.

The strategy is to combine sf and leaflet and R6 to make a simple dashboard that 
shows the Chloropleth for all states across time.

Features: Let you choose cut offs for binning the colors? This is because some 
counties have very high number of a numeric variable and letting automatic 
interpolation of color will make everything else washed out.

```{r}
library(stringr)
library(here)
library(data.table)
library(fst)
library(dplyr)
library(leaflet)
library(tidyr)
library(sf)
# list.files(here("data"))
```

# eviction data
```{r}
d <- fread(here("data", "county_court-issued_2000_2018.csv")) |>
  merge(data.table(state = state.name, state_abbv = state.abb))
d[, fips := stringr::str_pad(fips_county, width = 5, side = "right", pad = "0")]
set(d, j = c("state", "fips_state", "fips_county"), value = NULL)

dd <- readxl::read_xlsx(here("data", "county_proprietary_2000_2018_codebook.xlsx"))

d
```

Merge with population data 
```{r}
d_clean <- read_fst(
  here::here("data", "temp", "2000_2020_population_by_year_counties.fst"),
  as.data.table = TRUE
)

d_viz <- merge(d, d_clean, by = c("year", "fips"), all.x = TRUE)
setkeyv(d_viz, c("year", "state_abbv", "county"))
fst::write_fst(d_viz, here::here("data", "temp", "county_court-issued_2000_2018.fst"))
```

# sf for counties
{sf} is the newer standard compared to {sp}. We will need this to draw 
chloropleths or any type of geospatial modeling (lat/long).
```{r}
# Check if we have counties shape by year
# devtools::install_github("UrbanInstitute/urbnmapr")
# library(urbnmapr)
#
# counties_sf <- get_urbn_map("counties", sf = TRUE)
# counties_sf
```

```{r}
library(sf)
# Download the counties geojson
# counties_geojson <-
#   geojsonio::geojson_read(
#     "https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json",
#     what = "sp"
#   )
# saveRDS(counties_geojson, here::here("data", "temp", "counties_geojson_sp.rds"))

counties_geojson <- readRDS(here::here("data", "temp", "counties_geojson_sp.rds"))

# Convert to sf object
counties_geojson_shp <- st_as_sf(counties_geojson)
names(counties_geojson_shp)[1] <- "fips"

# Only keep fips_county column
st_write(
  select(counties_geojson_shp, fips),
  here::here("data", "temp", "counties_geojson_sf.shp")
)
```

# counties pop by year
* Downloaded here:
  + https://seer.cancer.gov/popdata/download.html
  + https://seer.cancer.gov/popdata/popdic.html
* Age is provided as 19 categories or by single year. Since we don't have
evictions by age group, we can just grab the 19 categories then aggregate up
to the county level
* from 1969 to 1989 race were only 3 categories
* from 1990 to 2020 race were expanded. We can just get this file.

## dict
* Scrape
```{r}
## Grab the data
# dict_raw <-
#   rvest::read_html("https://seer.cancer.gov/popdata/popdic.html") |>
#   rvest::html_table()

# dict_clean <- dict_raw[[1]] |>
#   janitor::clean_names() |> # Clean column name
#   mutate(across(.cols = where(is.character), .fns = str_trim)) # trim white space

## Clean up the strings to create variable name and descriptions
# t1 <- stringr::str_split_fixed(dict_clean$variable_name_and_values, "\r\n", n = 2)
# t1[3, 2] <- str_extract(t1[3, 1], "(?<=State FIPS code).*")
# t1[3, 1] <- str_extract(t1[3, 1], "State FIPS code")
# dict_clean$variable <- janitor::make_clean_names(t1[, 1])

## split by carriage return character
# dict_clean$description <- lapply(str_trim(t1[, 2]), \(x) {str_squish(str_split_1(x, "\r\n"))})
# dict_clean$variable_name_and_values <- NULL
# dict_clean$dtype <-
#   case_when(
#     dict_clean$data_type == "numeric" ~ "n",
#     dict_clean$data_type == "character" ~ "c",
#     T ~ NA_character_
#   )
#
# saveRDS(dict_clean, here::here("data", "temp", "pop_data_dict.rds"))
```

Generate the lookup table to create decode values
```{r}
dict_clean <- readRDS(here::here("data", "temp", "pop_data_dict.rds"))
dict_1990 <- dict_clean |>
  select(variable, description) |>
  unnest(description)
dict_1990$id <- seq_len(nrow(dict_1990))

dict_1990_clean <- dict_1990 |>
  filter(!id %in% c(28:32, 37, 38, 44, 50, 53:59))

dict_1990_lookup <- dict_1990_clean |>
  filter(str_detect(description, "=")) |>
  separate(description, sep = " = ", into = c("code", "value")) |>
  select(-id) |>
  nest(.by = variable)

rename_fns <- function(col, val) {
  if_else(col == "code", val, paste(val, "c", sep = "_"))
}

dict_1990_lookup <- mutate(
  dict_1990_lookup,
  data = purrr::map2(
    variable,
    data,
    \(x, y) {
      if (x %in% c("race", "origin", "sex")) {
        return(mutate(y, code = as.numeric(code)))
      }
      return(y)
    }
  )
)

dict_1990_lookup <- mutate(
  dict_1990_lookup,
  data = purrr::map2(
    variable,
    data,
    \(x, y) {
      rename_with(y, rename_fns, val = x)
    }
  ) |>
    purrr::set_names(variable)
)
```

## 1990 - 2020
* Extract and parse file
```{r}
# url1 <- "https://seer.cancer.gov/popdata/yr1990_2020.19ages/us.1990_2020.19ages.adjusted.txt.gz"
# download.file(
#   url1,
#   here::here("data", "temp", "us.1990_2020.19ages.adjusted.txt.gz")
# )
# R.utils::gunzip(
#   here::here("data", "temp", "us.1990_2020.19ages.adjusted.txt.gz"),
#   here::here("data", "temp", "us.1990_2020.19ages.adjusted.txt")
# )
#
# d_top <- readr::read_lines(
#   here::here("data", "temp", "us.1990_2020.19ages.adjusted.txt"),
#   n_max = 2
# )
#
# d <- readr::read_fwf(
#   here::here("data", "temp", "us.1990_2020.19ages.adjusted.txt"),
#   col_positions = readr::fwf_widths(
#     widths = dict_clean$length,
#     col_names = dict_clean$variable
#     )
#   )
#
# d$population <- as.numeric(d$population)
#
# fst::write_fst(
#   d,
#   here::here("data", "temp", "us.1990_2020.19ages.adjusted.parsed.fst")
# )
```

* Clean
```{r}
d_top <- read_fst(
  here::here("data", "temp", "us.1990_2020.19ages.adjusted.parsed.fst"),
  to = 10
)

selected_cols <- setdiff(
  names(d_top),
  c(
    "registry_geographic_definition_only",
    "state_postal_abbreviation"
  )
)

d <- read_fst(
  here::here("data", "temp", "us.1990_2020.19ages.adjusted.parsed.fst"),
  columns = selected_cols,
  as.data.table = TRUE
)[
  year %in% 2000:2020,
]
```

### aggregate
```{r}
agg_fns <- function(dt, var) {
  stopifnot(is.data.table(dt), var %in% names(dt))
  dt[,
    list(pop = sum(population, na.rm = TRUE)),
    by = c("year", "state_fips_code", "county_fips_code", var)
  ] |>
    merge(dict_1990_lookup$data[[var]], by = var)
}

cast_fns <- function(dt, var) {
  stopifnot(is.data.table(dt))
  dcast(
    dt,
    as.formula(str_glue("year + state_fips_code + county_fips_code ~ {var}_c")),
    value.var = "pop"
  )
}

d_race <- agg_fns(d, "race")
d_race_wide <- cast_fns(d_race, "race") |>
  janitor::clean_names()

d_origin <- agg_fns(d, "origin")
d_origin_wide <- cast_fns(d_origin, "origin") |>
  janitor::clean_names()

d_clean <- d[
  ,
  list(total_pop = sum(population)),
  by = c("year", "state_fips_code", "county_fips_code")
] |>
  merge(d_race_wide, by = c("year", "state_fips_code", "county_fips_code")) |>
  merge(d_origin_wide, by = c("year", "state_fips_code", "county_fips_code"))

d_clean$fips <- paste0(d_clean$state_fips_code, d_clean$county_fips_code)

set(d_clean, j = c("state_fips_code", "county_fips_code"), value = NULL)
perc <- setdiff(names(d_clean), c("year", "total_pop", "fips"))
perc_name <- paste("perc", perc, sep = "_")

d_clean[, (perc_name) := lapply(.SD, \(x) {
  round(x * 100 / total_pop, 3)
}), .SDcols = perc]

write_fst(d_clean, here::here("data", "temp", "2000_2020_population_by_year_counties.fst"),
  compress = 100
)
```
